# -*- coding: utf-8 -*-
"""Capstone_Project_SummerAnalytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V8GI_zlDUMTQ2xBIoALFVQGLxTO8blpp
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.cm as cm
import matplotlib.pyplot as plt
# % matplotlib inline

"""importing data."""

from google.colab import files
uploaded= files.upload()

data_train= pd.read_csv('Train_Data.csv')
data_train.head()
data_train.shape

"""converting values to integers for impression, clicks ,cost, conversion , revenue"""

data_train['impressions']=pd.to_numeric(data_train['impressions'])
data_train['clicks']=pd.to_numeric(data_train['clicks'])
data_train['cost']=pd.to_numeric(data_train['cost'])
data_train['conversions']=pd.to_numeric(data_train['conversions'])
data_train['revenue']=pd.to_numeric(data_train['revenue'])

"""Encoding features like date, campaign,adgroup, ad."""

from sklearn.preprocessing import LabelEncoder
data_train['date']=LabelEncoder().fit_transform(data_train['date'])
data_train['adgroup']=LabelEncoder().fit_transform(data_train['adgroup'])
data_train['campaign']=LabelEncoder().fit_transform(data_train['campaign'])
data_train['ad']=LabelEncoder().fit_transform(data_train['ad'])
data_train.head()

"""# Visualization

individual plot
"""

plt.plot(data_train['revenue'])
plt.show()
plt.plot(data_train['impressions'])
plt.show()
plt.plot(data_train['clicks'])
plt.show()
plt.plot(data_train['cost'])
plt.show()
plt.plot(data_train['conversions'])
plt.show()

"""Remove data with with revenue greater than 1650 as outlier."""

data_train=data_train[data_train['revenue']<1750]
data_train=data_train[data_train['impressions']<2050]
data_train=data_train[data_train['conversions']<80]

plt.plot(data_train['revenue'])
plt.show()
plt.plot(data_train['impressions'])
plt.show()
plt.plot(data_train['clicks'])
plt.show()
plt.plot(data_train['cost'])
plt.show()
plt.plot(data_train['conversions'])
plt.show()

"""heatmap"""

import seaborn as sns
f, ax= plt.subplots(figsize=(10,8))
corr= data_train.corr()
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True,
            ax=ax, annot=True)
plt.show()

data_train=data_train.drop(["campaign"],axis=1)
data_train.head()

"""splitting data"""

Y_train= pd.DataFrame(data=data_train.iloc[:,7].values, columns=['target'])
data_train.head()

data_train=data_train.drop(["revenue"],axis=1)

data_train.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(data_train, Y_train, test_size=0.05, random_state=42)
X_train.shape

"""Normalize data"""

from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.fit_transform(X_test)

"""Evalution metrics"""

from sklearn import metrics
def print_error(X_test, y_test, model_name):
  prediction= model_name.predict(X_test)
  print('MeanAbsoluteError:', metrics.mean_absolute_error(y_test, prediction))
  print('MeanSquaredError:', metrics.mean_squared_error(y_test, prediction))
  print('RootMeanSquareError:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))

"""TRAINING Different Models."""

# linear Regression.
from sklearn import linear_model
linear_regression= linear_model.LinearRegression()
linear_regression.fit(X_train, y_train)
print_error(X_test,y_test, linear_regression)

# Decision Tree Regressor.
from sklearn.tree import DecisionTreeRegressor
decision_tree=DecisionTreeRegressor()
decision_tree.fit(X_train, y_train)
print_error(X_test,y_test, decision_tree)

# Random forest Regressor
from sklearn.ensemble import RandomForestRegressor
n_estimators=200
max_depth=25
min_samples_split=15
min_samples_leaf=2
random_forest= RandomForestRegressor(n_estimators= n_estimators, max_depth=max_depth, min_samples_split=min_samples_split,
                                     min_samples_leaf=min_samples_leaf)
random_forest.fit(X_train, y_train)
print_error(X_test,y_test, random_forest)

# Support Vector Regressor
from sklearn.svm import SVR
supportvector_regressor=SVR()
supportvector_regressor.fit(X_train,y_train)
print_error(X_test,y_test, supportvector_regressor)

"""Artificial NEURAL network"""

import keras
from keras.layers import  Dense
ann=keras.models.Sequential([
                             Dense(6, activation='relu',
                                   input_shape= X_train.shape[1:]),
                             Dense(6,activation='relu'),
                             Dense(1)

])

optimizer=keras.optimizers.Adam()
loss=keras.losses.mean_squared_error
ann.compile(optimizer=optimizer, loss=loss, metrics=["mean_squared_error"])
history=ann.fit(X_train,y_train, epochs=100)

ann.summary()
print_error(X_test,y_test, ann)

"""Saving scikit and keras models"""

# Saving Scikit models
import joblib
joblib.dump(linear_regression, "Capstone_Project.pkl")

#  Saving Keras ANN
ann.save('ann_Capstone_Project.h5')

"""# now fetching new test data set and predicting it

"""

from google.colab import files
uploaded= files.upload()

new_test_data= pd.read_csv("Test_Data.csv")

print(new_test_data.head())
new_test_data.shape

new_test_data['impressions']=pd.to_numeric(new_test_data['impressions'])
new_test_data['clicks']=pd.to_numeric(new_test_data['clicks'])
new_test_data['cost']=pd.to_numeric(new_test_data['cost'])
new_test_data['conversions']=pd.to_numeric(new_test_data['conversions'])

new_test_data.shape

from sklearn.preprocessing import LabelEncoder
new_test_data['date']=LabelEncoder().fit_transform(new_test_data['date'])
new_test_data['adgroup']=LabelEncoder().fit_transform(new_test_data['adgroup'])
new_test_data['campaign']=LabelEncoder().fit_transform(new_test_data['campaign'])
new_test_data['ad']=LabelEncoder().fit_transform(new_test_data['ad'])
new_test_data.head()

new_test_data=new_test_data.drop(["campaign"],axis=1)
new_test_data.head()

from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()
new_test_data=scaler.fit_transform(new_test_data)

target= decision_tree.predict(new_test_data)

# To create Dataframe of predicted value with particular respective index
res = pd.DataFrame(target) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data
# res.index = new_test_data.index # its important for comparison. Here "test_new" is your new test dataset
res.columns = ["revenue"]

# To download the csv file locally
from google.colab import files
res.to_csv('new_test_data.csv', index=False)         
files.download('new_test_data.csv')

